{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word2vec_model_300dim_40minwords_10context', 'sampleSubmission.csv', 'labeled_train_clean_reviews.csv', 'word2vec_model_300dim_40minwords_10context_stemmed', 'labeledTrainData.tsv', 'word2vec_model_300dim_40minwords_10context_new', 'sentences_for_word2vec.csv', 'fasttext_300features_40minwords_10context.vec', 'labeled_train_clean_reviews_stemmed.csv', 'fasttext_300features_40minwords_10context.bin', 'test_submission.csv', 'testData.tsv', 'cc.en.300.bin', 'unlabeledTrainData.tsv', 'test_clean_reviews.csv', 'sentences_for_word2vec_stemmed.csv', 'sentences_for_fasttext.txt', 'test_clean_reviews_stemmed.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import os, re\n",
    "import nltk\n",
    "BASE_DIR = '../input/'\n",
    "LABELED_TRAIN_DF = BASE_DIR + 'labeledTrainData.tsv'\n",
    "UNLABELED_TRAIN_DF = BASE_DIR + 'unlabeledTrainData.tsv'\n",
    "TEST_DF = BASE_DIR + 'testData.tsv'\n",
    "print(os.listdir(BASE_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 25000 labeled train reviews, 50000 unlabeled train reviews, and 25000 test reviews\n"
     ]
    }
   ],
   "source": [
    "labeled_train = pd.read_csv(LABELED_TRAIN_DF, header = 0, delimiter = '\\t', quoting=3)\n",
    "unlabeled_train = pd.read_csv(UNLABELED_TRAIN_DF, header = 0, delimiter = '\\t', quoting=3)\n",
    "test = pd.read_csv(TEST_DF, header = 0, delimiter = '\\t', quoting=3)\n",
    "print \"Read %d labeled train reviews, %d unlabeled train reviews, \" \\\n",
    "          \"and %d test reviews\" % (labeled_train[\"review\"].size, unlabeled_train[\"review\"].size, test[\"review\"].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data leakage\n",
    "\n",
    "Check if test[\"sentiment\"] is correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"sentiment\"] = test[\"id\"].map(lambda x: 1 if int(x.strip('\"').split(\"_\")[1]) >= 5 else 0)\n",
    "y_test = test[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits: Kaggle tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "def review_to_clean_review(review, remove_stopwords=False, remove_numbers=True, stem_words=False):\n",
    "    review_text = BeautifulSoup(review, \"lxml\").get_text()\n",
    "    review_text = re.sub(\"[^a-zA-Z0-9]\", \" \", review_text)\n",
    "    \n",
    "    if remove_numbers:\n",
    "        review_text = re.sub(\"[0-9]\", \" \", review_text)\n",
    "    else:\n",
    "        review_text = review_text.replace('10', ' ten ')\n",
    "        review_text = review_text.replace('0', ' zero ')\n",
    "        review_text = review_text.replace('1', ' one ')\n",
    "        review_text = review_text.replace('2', ' two ')\n",
    "        review_text = review_text.replace('3', ' three ')\n",
    "        review_text = review_text.replace('4', ' four ')\n",
    "        review_text = review_text.replace('5', ' five ')\n",
    "        review_text = review_text.replace('6', ' six ')\n",
    "        review_text = review_text.replace('7', ' seven ')\n",
    "        review_text = review_text.replace('8', ' eight ')\n",
    "        review_text = review_text.replace('9', ' nine ')\n",
    "    \n",
    "    review_text = review_text.lower()\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        words = review_text.split()\n",
    "        stops = set(stopwords.words('english'))\n",
    "        words = [w for w in words if not w in stops]\n",
    "        review_text = \" \".join(words)\n",
    "    \n",
    "    if stem_words:\n",
    "        words = review_text.split()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        words = [stemmer.stem(word) for word in words]\n",
    "        review_text = \" \".join(words)\n",
    "    \n",
    "    return(review_text.strip())\n",
    "\n",
    "def review_to_wordlist(review, remove_stopwords=False, remove_numbers=True, stem_words=False):\n",
    "\n",
    "    words = review_to_clean_review(review, remove_stopwords, remove_numbers, stem_words).split()\n",
    "    return words\n",
    "\n",
    "def review_to_sentences(review, tokenizer, remove_stopwords=False, remove_numbers=True, stem_words=False):\n",
    "    \n",
    "    raw_sentences = tokenizer.tokenize(review.decode('utf8').strip())\n",
    "    \n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append(review_to_wordlist(raw_sentence, remove_stopwords, remove_numbers, stem_words))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'this', u'is', u'an', u'exampl', u'of', u'a', u'movi', u'review'], [u'it', u'has', u'two', u'sentenc']]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "example_review = \"This is an example of a movie review. It has two sentences.\"\n",
    "print(review_to_sentences(example_review, tokenizer, remove_numbers=False, stem_words=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labled train review 0 of 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/.local/lib/python2.7/site-packages/bs4/__init__.py:272: UserWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "/home/oscar/.local/lib/python2.7/site-packages/bs4/__init__.py:335: UserWarning: \"http://www.happierabroad.com\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labled train review 5000 of 25000\n",
      "Labled train review 10000 of 25000\n",
      "Labled train review 15000 of 25000\n",
      "Labled train review 20000 of 25000\n",
      "Unlabled train review 0 of 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/.local/lib/python2.7/site-packages/bs4/__init__.py:335: UserWarning: \"http://www.archive.org/details/LovefromaStranger\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/oscar/.local/lib/python2.7/site-packages/bs4/__init__.py:335: UserWarning: \"http://www.loosechangeguide.com/LooseChangeGuide.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlabled train review 5000 of 50000\n",
      "Unlabled train review 10000 of 50000\n",
      "Unlabled train review 15000 of 50000\n",
      "Unlabled train review 20000 of 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/.local/lib/python2.7/site-packages/bs4/__init__.py:335: UserWarning: \"http://www.msnbc.msn.com/id/4972055/site/newsweek/\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlabled train review 25000 of 50000\n",
      "Unlabled train review 30000 of 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/.local/lib/python2.7/site-packages/bs4/__init__.py:272: UserWarning: \"..\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlabled train review 35000 of 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/.local/lib/python2.7/site-packages/bs4/__init__.py:335: UserWarning: \"http://www.youtube.com/watch?v=a0KSqelmgN8\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlabled train review 40000 of 50000\n",
      "Unlabled train review 45000 of 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/.local/lib/python2.7/site-packages/bs4/__init__.py:335: UserWarning: \"http://jake-weird.blogspot.com/2007/08/beneath.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "# Initialize an empty list of sentences\n",
    "stemmed_sentences = []\n",
    "sentences = []\n",
    "# Parsing sentences from training set\n",
    "counter = 0.\n",
    "for review in labeled_train[\"review\"]:\n",
    "#     stemmed_sentences += review_to_sentences(review, tokenizer, remove_stopwords=False, remove_numbers=False, stem_words=True)\n",
    "    sentences += review_to_sentences(review, tokenizer, remove_stopwords=False, remove_numbers=False, stem_words=False)\n",
    "    if counter % 5000. == 0.:\n",
    "        print \"Labled train review %d of %d\" % (counter, len(labeled_train[\"review\"]))\n",
    "    counter = counter + 1.\n",
    "\n",
    "counter = 0.\n",
    "# Parsing sentences from unlabeled set\n",
    "for review in unlabeled_train[\"review\"]:\n",
    "#     stemmed_sentences += review_to_sentences(review, tokenizer, remove_stopwords=False, remove_numbers=False, stem_words=True)\n",
    "    sentences += review_to_sentences(review, tokenizer, remove_stopwords=False, remove_numbers=False, stem_words=False)\n",
    "    if counter % 5000. == 0.:\n",
    "        print \"Unlabled train review %d of %d\" % (counter, len(unlabeled_train[\"review\"]))\n",
    "    counter = counter + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([u'a', u'spin', u'off', u'of', u'donald', u'p', u'bellisario', u's', u'military', u'show', u'jag', u'ncis', u'is', u'a', u'favourite', u'of', u'mine', u'at', u'the', u'moment'])\n",
      " list([u'i', u'just', u'don', u't', u'know', u'how', u'i', u'could', u'expect', u'something', u'worth', u'a', u'look', u'from', u'a', u'film', u'with', u'such', u'plot', u'two', u'stupid', u'ignorant', u'kids', u'make', u'a', u'bet', u'that', u'each', u'of', u'them', u'will', u'do', u'something', u'certainly', u'extremely', u'idiotic', u'to', u'prove', u'to', u'each', u'other', u'wtf'])\n",
      " list([u'there', u'to', u'be', u'picked', u'off', u'at', u'a', u'moment', u's', u'notice'])\n",
      " list([u'talk', u'about', u'a', u'change', u'of', u'attitude', u'in', u'these', u'children', u's', u'adolescence'])\n",
      " list([u'she', u'is', u'hardly', u'in', u'the', u'film', u'at', u'all', u'which', u'is', u'the', u'movie', u's', u'only', u'saving', u'grace', u'and', u'the', u'ten', u'minutes', u'or', u'so', u'they', u'used', u'her', u'was', u'still', u'excessive'])\n",
      " list([u'this', u'movie', u'is', u'intelligent'])\n",
      " list([u'usually', u'this', u'is', u'stated', u'as', u'if', u'the', u'static', u'camera', u'leads', u'ipso', u'facto', u'to', u'boring', u'static', u'films'])\n",
      " list([u'he', u'has', u'the', u'help', u'of', u'the', u'beautiful', u'ilona', u'massey', u'but', u'he', u's', u'not', u'quite', u'sure', u'what', u'side', u'of', u'the', u'fence', u'she', u's', u'playing', u'the', u'nazis', u'are', u'stupid', u'even', u'more', u'stupid', u'than', u'usual', u'in', u'these', u'films', u'but', u'they', u've', u'also', u'got', u'a', u'lot', u'of', u'intrigues', u'going', u'among', u'each', u'other', u'between', u'cedric', u'hardwicke', u'and', u'j', u'edward', u'bromberg', u'to', u'see', u'who', u'will', u'be', u'top', u'dog', u'under', u'himmler', u'in', u'the', u's', u's', u'and', u'peter', u'lorre', u'does', u'not', u'think', u'terribly', u'much', u'of', u'german', u'efficiency', u'and', u'with', u'these', u'two', u'around', u'who', u'could', u'blame', u'him'])\n",
      " list([u'this', u'version', u'of', u'the', u'famous', u'novel', u'of', u'victor', u'hugo', u'i', u'found', u'very', u'suitable', u'in', u'general', u'with', u'good', u'acting', u'and', u'a', u'narration', u'which', u'give', u'a', u'real', u'idea', u'of', u'the', u'book'])\n",
      " list([u'it', u'is', u'an', u'oddity', u'of', u'the', u'cinema', u'and', u'is', u'very', u'much', u'worth', u'seeing'])]\n"
     ]
    }
   ],
   "source": [
    "print(np.random.choice(sentences, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_sentences = [\" \".join(sentence).strip() for sentence in sentences]\n",
    "output_sentences = pd.DataFrame(data={\"sentences\": joined_sentences})\n",
    "output_sentences.to_csv(os.path.join('../', 'input', \"sentences_for_word2vec_convert_10.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train review 0 of 25000\n",
      "Train review 5000 of 25000\n",
      "Train review 10000 of 25000\n",
      "Train review 15000 of 25000\n",
      "Train review 20000 of 25000\n",
      "Test review 0 of 25000\n",
      "Test review 5000 of 25000\n",
      "Test review 10000 of 25000\n",
      "Test review 15000 of 25000\n",
      "Test review 20000 of 25000\n"
     ]
    }
   ],
   "source": [
    "labeled_train_clean_reviews = []\n",
    "counter = 0.\n",
    "for review in labeled_train[\"review\"]:\n",
    "#     clean_review_stemmed = review_to_clean_review(review, remove_stopwords=False, remove_numbers=False, stem_words=True)\n",
    "    clean_review = review_to_clean_review(review, remove_stopwords=False, remove_numbers=False, stem_words=False)\n",
    "    labeled_train_clean_reviews.append(clean_review)\n",
    "    if counter % 5000. == 0.:\n",
    "        print \"Train review %d of %d\" % (counter, len(labeled_train[\"review\"]))\n",
    "    counter = counter + 1.\n",
    "\n",
    "test_clean_reviews = []\n",
    "counter = 0.\n",
    "for review in test[\"review\"]:\n",
    "#     clean_review_stemmed = review_to_clean_review(review, remove_stopwords=False, remove_numbers=False, stem_words=True)\n",
    "    clean_review = review_to_clean_review(review, remove_stopwords=False, remove_numbers=False, stem_words=False)\n",
    "    test_clean_reviews.append(clean_review)\n",
    "    if counter % 5000. == 0.:\n",
    "        print \"Test review %d of %d\" % (counter, len(test[\"review\"]))\n",
    "    counter = counter + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'i live in salt lake city and i m not a mormon  so why did i rent this movie  well because i live in utah and thought it d be nice to see locations i know in a film  i really knew going into it that i wasn t going to get the inside jokes so i wasn t surprised when i sat with the deer in the headlights stare  what i was surprised at was the ant non mormon actions that were placed in this film i know it s a mormon film  catered to the members of the lds church  but i found it offensive because of the typical stereotype of people that isn t of their faith  every non mormon  which wasn t many  drank  smoked and had an amazing selfishness attitude  why that really ticked me off about this film  they made the mormons so pure  yet the rest of the state of utah i guess is filled with punk psychos just because they don t follow the scriptures of the lds church i can understand having the plots revolve around all lds members  but you d think salt lake city was  ten  zero   mormon  which isn t even close to being the truth  and as i said  the non mormons in the movie were portrayed as drunken jerks  please i guess i just don t get it because i don t belong to their faith and i guess i never will'\n",
      " u'i m watching the series again now that it s out on dvd  yay   it s striking me as fresh  as relevant and as intriguing as when it first aired the central performances are gripping  the scripts are layered i ll stick my neck out and put it up there with the prisoner as a show that ll be winning new fans and still be watched come  two  zero  three  five  i ve been asked to write some more line  it seems imdb is as user unfriendly and anally retentively coded as ever  pithy and to the point is clearly not the imdb way  well  unlike imdb s submissions editors  american gothic understands that simplicity is everything in  two  two  episodes  the show covers more character development than many shows do in seven seasons  on top of which it questions personal ethics and strength of character in a way which challenges the viewer at every turn to ask themselves what they would choose and what they would think in a given situation when the show first aired  i was still grieving for twin peaks and thought it would be a cheap knock off  personally i m starting to rate it more highly and suspect it will stand up better over the years  reckon it don t get more controversial than that'\n",
      " u'after reading the reviews  it became obvious that everyone intellectualized this work  how utterly boring  oh how about the good ol  days and there was nothing like it  of all the comments no one expressed any emotion to this work or any other i grew up just after the end of the steam age and this cinematic gem along with dan l boone graced the saturday afternoon matin  es  this was an annual movie that made the rounds and filled the seats with gabbing  yapping  farting  giggling  snot monsters like myself or was self  and it was a movie theatre filler at the time  almost as big as the wizard of oz imdb insists that every critique contains something about the plot  problem is was that it was rather a template  here goes  randolph scott  cowboy hero gathers friends and goes defeats those evil people  hooray  all of us kids figured out that plot before we plunked our quarter down to watch it  that was just about the plot line of every scott  john wayne  roy rogers film ever made  if you take the time to go back and review each and every movie   just don t ask for surprises one must remember the context of the times  there was no or little tv  none for kids  there was school  there was the great outdoors  there were toy guns  no cyber time  and the steam age had just collapsed  but movies such as this provided the entertainment and filled the imaginations of young whippersnappers  even the girls got into it this movie was the entertainment  and it is just as mindless as anything produced today  it had a purpose originally of being propaganda  but quickly came to be kids movies our fathers had experienced the real thing  and it wouldn t be until sam peckinpah a decade later who finally lavished the red splashes of imitation blood in realistic and copious quantities  not until his directorship did anyone die slowly  with great pain and miserably  until peckinpah war and gun fights were a rather bloodless affair  thanks sam to see a movie had little or no blood  the adults didn t mind  they wouldn t have tolerated it i think  no guts spraying the shattering plant life  so this movie had all of the glory and none of the gory  gung ho was suitable for kids then you will see that i assigned a four to this rating  why would i do that  well  it is a terrible movie  no matter how i love it  i do love this movie because it brought back one of the happier moments of my childhood  but it is not all that good of a movie in quality terms  basically gung ho transitted to become a romance novel for children should people watch it  of course  i am not saying to stay away  realistically however  the plot is simple  the characters shallow  they are shoals  you can love a bad movie'\n",
      " u'a very young ginger rogers trades quick quips and one liners with rival newspaper reporter lyle talbot in this  one  nine  three  three  murder mystery from poverty row film maker allied productions  the movie opens with a wealthy businessman taking a header from the roof garden of a high rise apartment house  or was it from a lover s apartment  rogers actually has two identities at the film s outset  that of miss terry  the dead victim s secretary  along with her newspaper byline of pat morgan  mistakenly phoning her story directly to ted rand  talbot  instead of her paper s rewrite desk  she gets fired for her efforts when her boss learns he s been out scooped here s a puzzle   it s revealed during police inspector russell s  purnell pratt  investigation of harker s death that terry morgan had been employed as his secretary for three weeks  why exactly was that  after the fact it would make sense that she was there for a newspaper story  but before  clues are dropped regarding harker s association with a known mobster conveniently living in the same apartment building  but again  that association isn t relevant until it s all linked up to janitor peterson  harvey clark   and who s making up all the calling cards with the serpent effecting a hsss  with the words   you will hear it   cut and pasted beneath  apparently  the hissing sound of a snake was the sound made by the apartment house s radiator system  which peterson used to transmit a poisonous gas into the rooms of potential victims  such as mrs  coby in the apartment below harker  but in answer to a question posed to inspector russell about mrs  coby s death  he replied   apparently   to the cause of strangulation it s these rather conflicting plot points that made the movie somewhat unsatisfying for me  the revelation of janitor peterson as the bad guy of this piece comes under somewhat gruesome circumstances as we see him stuff the unconscious body of miss morgan in the building s incinerator furnace  however  and score another point against continuity  we see miss morgan in a huge basement room as peterson ignites the furnace  she made her getaway  but how  and still pretty as a picture  and who gets to make the collar off screen if none other than milquetoast police assistant wilfred  arthur hoyt   who in an opening scene fell over his own feet entering a room sorry  but for all those reviewers who found   a shriek in the night   to be a satisfying whodunit  i feel that any charlie chan film of the same era is a veritable   the usual suspects   by comparison  if you need a reason to see the film  it would be ginger rogers  but be advised  she doesn t dance'\n",
      " u'seldom do we see such short comments written by imdb filmgoers  perhaps it s because this lightweight dark comedy entertains and pleases without depth  or are we missing something  i d watch it again if i had some incentive so what s a happenstance  to the french it is   le battement d ailes du papillon   serendipity  fate  perhaps it s an event that is the culmination of a series of random happenings  we ve all had these  it s called life  but when looked at in this way  you begin to get the feeling that   random   might be more like   fated   a  happenstance  in this film might be an occurrence as minor as knocking a few leaves of lettuce off the back of a truck or as major as basing a major life decision on the accuracy of a stranger tossing of a pebble  all these incidents cause other events that     well you get the picture  dominoes  multiply those by  three  zero  characters and an average of  six  each and you have to really stretch your imagination to accept the remote chance that this scenario could happen  and i think that there s a diagnosis for those who believe that life is like this  but then this is the magic world of cinema we admit that it is fun to watch the way the writer director weaves together these unrelated events into a story which enmeshes the lives of these french citizens  if you have a couple of hours and are looking for a whimsical escape  here s the place to do it  or if you re recovering from surgery and aren t going anywhere anyway  this will engage you while your stitches are healing    happenstance   will not go down as an award winner but it should develop a cult following  stranger things have happened  soren kierkegaard is attributed with the following    life can only be understood backwards  but it must be lived forward    if you looked at the detail in many of your own life experiences  meeting your first love  finding the perfect gift  your last auto accident  you would find a series of seemingly random events leading up to it that s the answer  i forgot to bring along an existentialist to explain   happenstance   to me'\n",
      " u'several young iranian women dress as boys and try to get into a world cup qualifying match between iran and bahrain  when they re caught  they re penned in an area where the match remains within earshot  but out of sight  the prisoners plead to be let go  but rules are rules given the pedigree of its director  jafar panahi  it was disarming to discover that offside is a comedy  and a frequently hilarious one  in  one  nine  nine  seven  s the mirror  panahi presents two versions of iranian girlhood and leaves the audience to wonder which one is   real    in  two  zero  zero  zero  s the circle  several iranian women step outside the system  their transgressions are different  but they all end up in the same tragic place however  thinking now about offside  it s hard to imagine it as anything other than a comedy  because the situation it presents is so obviously ridiculous  as the women demand to know why they can t watch the soccer match and their captors struggle to answer  the only possible outcome is comedy what makes offside most affecting is that the young women are not portrayed as activists attacking the system  they are simply soccer fans and patriots  and despite the fact that they are clearly being treated unfairly  they never lose their focus on the match and the historic victory that is within their nation s grasp'\n",
      " u'okay   enjoy  is a pretty relative term  but flexibility is in order when you re dealing with a filmmaker of james glickenhaus  calibre mcbain is truly one of the most ridiculous  over the top action films i ve ever seen  without the nasty edge of the exterminator  other reviews have commented on a suspension of disbelief regarding the film s heroic middle aged commandos  but how about making a film in the philippines that is set in colombia  all the extras are filipino  in fact the only character who looks remotely hispanic is good ol  victor argo as the much reviled  el presidente   oh yes  we also have maria conchita alonso overemoting like crazy as a rebel leader  there are tons of explosions and bodies flying everywhere in this amusing paean to the glories of american imperialism'\n",
      " u'creature unknown is the right word for this movie  or maybe it should be called unknown movie  this movie is a piece of crap right from the beginning  it has a really stupid   plot    really pathetic   acting    and so so   special effects    some thirty something year old   post teens   are trapped in the woods with a mad  reptilian  rubber suit creature lurking around endlessly  what you get with this movie is a bunch of talk and precious little action  you have girls walking through the woods talking  and then you have guys  with heavy mascara on  walking through the woods talking  the whole thing is so boring the creature itself is rarely seen throughout most of the movie  when it is shown the picture is distorted to mask the fact that it is a man in a rubber suit  and the movement shows that it is a suit  hence the reason for the blurring and distortion of the image  this is not a good movie in any since of the word and the ones here who have praised it are most likely the people that were picked up off the street to   act   in this truly stupefying movie  skip this one for certain'\n",
      " u'i have this film out of the library right now and i haven t finished watching it  it is so bad i am in disbelief  audrey hepburn had totally lost her talent by then  although she d pretty much finished with it in  robin and marian   this is the worst thing about this appallingly stupid film  it s really only of interest because it was her last feature film and because of the dorothy stratten appearance just prior to her homicide there is nothing but idiocy between gazzara and his cronies  little signals and little bows and nods to real screwball comedy of which this is the faintest  palest shadow who could believe that there are even some of the same manhattan environs that hepburn inhabited so magically and even mythically in  breakfast at tiffany s  twenty years earlier  the soundtrack of old sinatra songs and the gershwin song from which the title is taken is too loud and obvious  you sure don t have to wait for the credits to find out that something was subtly woven into the cine musique of the picture to know when the songs blasted out at you  reverting to type  means going back up as well as going back down  i guess  in this case  audrey hepburn s chic european lady is all you see of someone who was formerly occasionally an actress and always a star  here she has even lost her talent as a star  if someone whose talent was continuing to grow in the period  like ann margret  had played the role  there would have been some life in it  even given the unbelievably bad material and mongoloid level situations hepburn was a great person  of course  greater than most movie stars ever dreamed of being  and she was once one of the most charming and beautiful of film actors  after this dreadful performance  she went on to make an atrocious tv movie with robert wagner called  love among thieves   in  they all laughed  it is as though she were still playing an ingenue in her  five  zero  s  even much vainer and obviously less intelligent actresses who insisted upon doing this like lana turner were infinitely more effective than is hepburn  turner took acting seriously even when she was bad  hepburn doesn t take it seriously at all  couldn t be bothered with it  even her hair and clothes look tacky  her last really good work was in  two for the road   perhaps her most perfect  if possibly not her best in many ways and that girl who plays the country singer is just sickening  john ritter is horrible  there is simply nothing to recommend this film except to see dorothy stratten  who was truly pretty  otherwise  critic david thomson s oft used phrase  losing his her talent  never has made more sense ben gazarra had lost all sex appeal by then  and so we have  two  films with gazarra and hepburn  who could ask for anything less  sandra dee s last  pitiful film  lost   from  two  years later  a low budget nothing  had more to it than this  at least ms  dee spoke in her own voice  by  one  nine  eight  one   audrey hepburn s accent just sounded silly  she d go on to do the pbs  gardens of the world with audrey hepburn  and there her somewhat irritating accent works as she walks through english gardens with aristocrats or waxes effusively about  what i like most is when flowers go back to nature   as in naturalized daffodils  but in an actual fictional movie  she just sounds ridiculous to think that  breakfast at tiffany s  was such a profound sort of light poetic thing with audrey hepburn one of the most beautiful women in the world  she was surely one of the most beautiful screen presences in  my fair lady   matching garbo in several things and delphine seyrig in  last year at marienbad   and then this  and her final brief role as the angel  hap  in the spielberg film  always  was just more of the lady stuff  corny  witless and stifling i went to her memorial service at the fifth avenue presbyterian church  a beautiful service which included a boys  choir singing the shaker hymn  simple gifts   the only thing not listed in the program was the sudden playing of hepburn s singing  moon river  on the fire escape in  breakfast at tiffany s   and this brought much emotion and some real tears out in the congregation a great lady who was once a fine actress  as in  the nun s story   and one of the greatest and most beautiful of film stars in many movies of the  five  zero  s and  six  zero  s who became a truly bad one  that s not all that common  and perhaps it is only a great human being who  in making such things as film performances trivial  nevertheless has the largeness of mind to want to have the flaws pointed out mercilessly  which all of her late film work contained in abundance  most of the talk about hepburn s miscasting is about  my fair lady   but the one that should have had the original actress in it was  wait until dark   which had starred lee remick on broadway  never as celebrated as hepburn  she was a better actress in many ways  hepburn was completely incapable of playing anything really sordid   although hepburn was at least adequate enough in that part  after that  all of her acting went downhill'\n",
      " u'i can understand why some people like this movie  and why some people don t  for me  though  i really like it  even if i noticed some good bits  and not so impressive bits  the animation was actually excellent  like charlie s dream  the characters were a mixed bag  the best being anne marie  voiced by the late judith barsi  i was physically ill when i read what happened to her  also  carface is a very convincing villain especially voiced by the wonderful vic tayback i particularly loved   morons i m surrounded by morons    and along with rasputin and warren t rat is probably the most memorable of all the don bluth villains  charlie and itchy only just lacked the same sparkle  but i loved king gator and his song  some of the film is very haunting  like annabelle s   you can never come come back    which kind of scares me still  unfortunately  there were some bits i didn t like so much  the story had a tendency to become clumsy and unfocused  but disney s black cauldron suffered from the same problem  also there were some dark scenes  that young children would find upsetting  but the ending is very poignant  however the biggest flaw was the rather bland songs and the way they were sung  none of them in particular stick out  with exception of   let s make music together   and   love survives    and burt reynolds can t sing and dom deluise has done much better singing  all in all  a watchable movie  that could have been more  but is definitely memorable  and i would definitely watch it again   seven   ten   bethany cox']\n",
      "[u'while driving in a dangerous zigzag manner on a lonely road in the night  the teenager cliff  jay r  ferguson  has a car accident with his friends lauren  christine taylor   alex  kim murphy  and eric  christopher masterson   while spending the cold night stranded in the woods around a campfire  they kill time telling ghost stories  in   the honeymoon    the couple rick  ron livingston  and valerie  jennifer macdonald  travels in their rv to las vegas in their honeymoon  rick takes a shortcut to visit the clayton caverns in the night  but the stranger cole  hawthorne james  advises them to leave the spot since dangerous creatures attack people in the full moon  in   people can lick too    on the eve of her twelfth birthday  amanda  alex mckenna  tells her internet friend jessica that she is alone at home  however  jessica is actually a psychopath  in   the locket    the biker scott  glenn quinn  is crossing the country on his motorcycle  when he has a problem with his bike  he finds an isolated house where the gorgeous dumb heather wallace  jacinda barrett  lives with her father  when the man returns from his herd  scott finds the truth about heather   campfire tales   presents three good horror tales  with monsters  psychopaths and ghosts and a surprising twist in the end  the weakest segment is   the hook    with eddie and jenny  but the other stories a great  the plot point is totally unexpected and gives a great conclusion to this above average horror movie  my vote is seven title  brazul     contos da meia noite      midnight tales'\n",
      " u'there are some movies that are loved by almost everyone who you come across and yet happen to be box office failures  andaz apna apna  an intelligent and hilarious comedy falls in that catogory  for once  an indian director has kept in mind the sensibilities of the audience  and not churned out a kader khan type stereo typical hoax  the movie is about two guys who dream of riches  and try to accomplish that by wooing a millionaire s daughter  a humorous drama unfolds while a lot of complexities surface in the story  the complexities add to the sheer comedy of the entire plot  aamir khan plays the a street smart guy  while salman khan gives an unexpectedly good performance as the dumb guy  the villian played by paresh rawal and his henchmen  junior ajit and   kaliaa   make you laugh in your sleep  although the movie borrows from a lot of other movies  despite shoddy camerawork  and despite being   loud   at times  it remains one of the scarce   funny   movies bombay has come up with after movies like padosan  golmal and other amol plaekar movies  it is sad that it didn t do well at the box office  for that means producers turn back to formulas and creativity is abandoned'\n",
      " u'what can you say about a grainy  poorly filmed  one  six mm stag film  where the best and most attractive performer is a german shepherd  nothing that would be positive  avoid this travesty at all costs  in any case  it would be difficult to find  since bestiality remains a taboo and illegal subject in the usa  i strongly suggest imdb to re visit their weighting formula for establishing ratings  since an  eight   eight  rating for this piece of fecal matter is absurd  i am  by no means  a prude and have spent many hours enjoying the classic porn movies of the  seven  zero  s    eight  zero  s  but this is inferior product even by the looser standards of the  then illegal  stag loop'\n",
      " u'apparently in early  two  zero  zero  five   scifi channel threatened to release the incriminating photos they have of john rhys davies and said    we need you to star in another scifi original    the scary thing is  he s actually pretty damn good in this movie  that s really saying something since this is a silly scifi creature feature  you ve gotta put some feeling into it in order to be well acted  unfortunately  nobody else does  it s your stereotypical   moster run amok   movie on a cruise ship  the cryptozoologist wants to keep the creature alive  the navy seals think they have everything under control but they don t know what they re dealing with and they all end up dead  a girl jumps into the   movie sexpot   role as rhys davies  daughter and the creature mauls about  ten  zero  or so shipmates  what this movie has going for it is  it s very fast paced and lively  you re never bored or waiting for another kill  other than that  though  it does nothing to distinguish itself  and it s silly that this thing crawls all over the ceilings and can t be wounded by navy seal machine guns  but can be karate kicked into submission by rhys davies  daughter  kinda went back and forth on giving this bad boy a  five   but for the above silliness i m giving it a  four'\n",
      " u'i first saw this movie on ifc  which is a great network by the way to see underground films  i watched this movie and was thinking it was going to be pure drama and a story line that doesn t hold water  but it really was a worth while watch  the main character is in such rough shape  and you hate to see him deny help  but no matter what you just can t hate him  his devotion to the beatles and john lennon is a great metaphor for his life and the helplessness he feels  the atmosphere of the film is also great  at times  you feel like you can see what he sees  feel what he feels in some situations  this movie does not leave you wanting to know more  or disliking a loophole in the plot  there are no loopholes  in my opinion   i have always been a fan of foreign films  especially now with movies being made so poorly in america  i really enjoy the foreign settings because i feel it can take you on a trip  and sometimes understand a different culture  this movie did all those things to me and more  please watch this movie and if you re new to foreign films  this is a great start'\n",
      " u'not all  but most of this story is buster being mistaken for   dead shot dan    a notorious criminal  there really is no story  just a series of adventures to show off buster s physical talents  which are amazing  and his comedic timing  the  two  seven  minute film is basically one adventure after the other mostly involving someone chasing our hero earlier  it s a couple of policemen on their beats racing through the streets after keaton and later it s   big joe   roberts  a rotund cop   and father a girl buster is interested in   who chases him  those latter scenes were the best i thought  with a lot of clever gags involving the hotel elevator where big joe and his daughter live  that was keaton at his best it s just a madcap half hour that makes little sense  but cares  it s buster at his slapstick best  or near it  and so it serves its purpose  to entertain us  just think   eight  five  years after this film was made there are people  like me  still discovering and enjoying these silent comedy classics  cool'\n",
      " u'i really liked this quirky movie  the characters are not the bland beautiful people that show up in so many movies and on tv  it has a realistic edge  with a captivating story line  the main title sequence alone makes this movie fun to watch'\n",
      " u'if western union isn t exactly the real story of the construction of the transcontinental telegraph  it certainly does capture the spirit and dedication of the people involved with the project dean jagger is the man in charge and one fine day he s thrown from a horse and sustains some fractured ribs  an outlaw on the run  randolph scott  finds jagger and is ready to steal his horse  but changes his mind and brings jagger to help  later on he s hired by western union and works for jagger jagger also hires a young easterner played by robert young who s an engineer  young is doing one of his few loan out films away from mgm for  two  zero th century fox  both young and scott become friends  but rivals for jagger s sister virginia gilmore western union has plenty of action  enough to satisfy any western fans  the telegraph crew has to deal with outlaws  indians  and your garden variety labor troubles slim summerville as the timid cook and victor killian as the frontier character assigned to guard him have some of the funniest scenes  they both provide some good comic relief  fritz lang got good performances from his cast and kept the film moving briskly along  western union is solid western entertainment'\n",
      " u'in  one  nine  eight  nine   aardman animations introduced the two heros in the grand day out  in  one  nine  nine  three   they fought an evil penguin in the wrong trousers  and in  one  nine  nine  five   they had to rescue sheep from an evil robot dog in a close shave  in  two  zero  zero  five   they re back and they are going to fight something that used to be cute and cuddlely in the curse of the were rabbit  in this full feature film  wallace and gromit work in anit pesto  a pest control business  there s going to be a giant vegetable competition  but rabbits keep eating the neighbors vegies  wallace and gromit takes care with that problem  but wallace had an idea  he will brainwash the bunnies with his machine  after doing that  something suddenly eats all of the vegies in the neighborhood and it s big  it s up to wallace and gromit to save the day  as a fan of these two characters  i was impressed  it kept what the  three  previous chapters had and instead adding a lot of hollywood actors for voice overs  they put a no name cast to the job and boy  they did a fantastic job  wallace and gromit has not changed  wallace is still the cheese loving freak like he always was and gromit is the silent newspaper reading dog  also  the script was not too shabby like other family movies were  there is a twist of who the were rabbit really is  the direction from nick park  the director of the  three  previous chapters  does a really good job with the storyline  instead of adding the hollywood formula in it  he just took the style of the previous chapters and adds a bit of a dark fantasy twist in it  well done  nick  the rabbits are also funny and adorable  but the funniest rabbit in the movie is one who has the mix of wallace in him  the characters were not bad and they weren t annoying  but they ll never top wallace and gromit  the animation is indeed fantastic and wonderful  i ve never seen a clay animated movie that is so amazing since chicken run  overall  fans of the two knuckleheads  including the teens  will love this fantastic film  it is a well done film that should get an oscar next year  hooray  wallace and gromit   ten   ten'\n",
      " u'the lives of megan jackie kresler and dylan shane elliott change in the nevada desert between reno and las vegas  they stop to eat at a small greasy spoon where they reluctantly learn about the infamous area  five  one  by the caf   proprietor jonathan breck   after getting back on the road in their forty year old lincoln  the radio gets a little crazy broadcasting hitler s speech at the  one  eight  three  six  olympics and then later a  one  nine  five  eight  news bulletin of elvis presley being drafted into the military  the car slowly breaks down and the two are in for the scare of their lives as mysterious unexplainable things happen in the lonely radiation poisoned desert  remnants of nuclear testing  megan meets a lost little girl channing nichols and a wounded wwii soldier  the nightmarish journey doesn t end there  kresler is impressive to a degree and writer director james lay makes good use of patsy cline tunes  all in all  moderately interesting sci fi']\n"
     ]
    }
   ],
   "source": [
    "print(np.random.choice(labeled_train_clean_reviews, 10))\n",
    "print(np.random.choice(test_clean_reviews, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_labeled_train_clean_reviews = \\\n",
    "    pd.DataFrame(data={\"id\": labeled_train[\"id\"], \"sentiment\": labeled_train[\"sentiment\"], \"review\": labeled_train_clean_reviews})\n",
    "output_test_clean_reviews = \\\n",
    "    pd.DataFrame(data={\"id\": test[\"id\"], \"review\": test_clean_reviews})\n",
    "# output_labeled_train_clean_reviews.to_csv(os.path.join('../', 'input', \"labeled_train_clean_reviews_stemmed.csv\"), index=False, quoting=3)\n",
    "# output_test_clean_reviews.to_csv(os.path.join('../', 'input', \"test_clean_reviews_stemmed.csv\"), index=False, quoting=3)\n",
    "\n",
    "output_labeled_train_clean_reviews.to_csv(os.path.join('../', 'input', \"labeled_train_clean_reviews_convert_10.csv\"), index=False, quoting=3)\n",
    "output_test_clean_reviews.to_csv(os.path.join('../', 'input', \"test_clean_reviews_convert_10.csv\"), index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-10 05:40:30,962 : INFO : 'pattern' package found; tag filters are available for English\n",
      "2019-01-10 05:40:30,970 : INFO : collecting all words and their counts\n",
      "2019-01-10 05:40:30,972 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-01-10 05:40:31,052 : INFO : PROGRESS: at sentence #10000, processed 228974 words, keeping 17776 word types\n",
      "2019-01-10 05:40:31,132 : INFO : PROGRESS: at sentence #20000, processed 457937 words, keeping 24948 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Word2Vec model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-10 05:40:31,214 : INFO : PROGRESS: at sentence #30000, processed 680112 words, keeping 30034 word types\n",
      "2019-01-10 05:40:31,298 : INFO : PROGRESS: at sentence #40000, processed 909365 words, keeping 34348 word types\n",
      "2019-01-10 05:40:31,377 : INFO : PROGRESS: at sentence #50000, processed 1131511 words, keeping 37761 word types\n",
      "2019-01-10 05:40:31,456 : INFO : PROGRESS: at sentence #60000, processed 1355867 words, keeping 40723 word types\n",
      "2019-01-10 05:40:31,535 : INFO : PROGRESS: at sentence #70000, processed 1581925 words, keeping 43333 word types\n",
      "2019-01-10 05:40:31,614 : INFO : PROGRESS: at sentence #80000, processed 1804032 words, keeping 45714 word types\n",
      "2019-01-10 05:40:31,691 : INFO : PROGRESS: at sentence #90000, processed 2031179 words, keeping 48135 word types\n",
      "2019-01-10 05:40:31,765 : INFO : PROGRESS: at sentence #100000, processed 2255867 words, keeping 50207 word types\n",
      "2019-01-10 05:40:31,842 : INFO : PROGRESS: at sentence #110000, processed 2478609 words, keeping 52081 word types\n",
      "2019-01-10 05:40:31,917 : INFO : PROGRESS: at sentence #120000, processed 2703586 words, keeping 54119 word types\n",
      "2019-01-10 05:40:31,991 : INFO : PROGRESS: at sentence #130000, processed 2932333 words, keeping 55847 word types\n",
      "2019-01-10 05:40:32,063 : INFO : PROGRESS: at sentence #140000, processed 3147780 words, keeping 57346 word types\n",
      "2019-01-10 05:40:32,135 : INFO : PROGRESS: at sentence #150000, processed 3376171 words, keeping 59055 word types\n",
      "2019-01-10 05:40:32,207 : INFO : PROGRESS: at sentence #160000, processed 3601641 words, keeping 60617 word types\n",
      "2019-01-10 05:40:32,280 : INFO : PROGRESS: at sentence #170000, processed 3827797 words, keeping 62077 word types\n",
      "2019-01-10 05:40:32,351 : INFO : PROGRESS: at sentence #180000, processed 4051211 words, keeping 63496 word types\n",
      "2019-01-10 05:40:32,427 : INFO : PROGRESS: at sentence #190000, processed 4279296 words, keeping 64794 word types\n",
      "2019-01-10 05:40:32,501 : INFO : PROGRESS: at sentence #200000, processed 4506191 words, keeping 66087 word types\n",
      "2019-01-10 05:40:32,576 : INFO : PROGRESS: at sentence #210000, processed 4730651 words, keeping 67390 word types\n",
      "2019-01-10 05:40:32,654 : INFO : PROGRESS: at sentence #220000, processed 4958577 words, keeping 68697 word types\n",
      "2019-01-10 05:40:32,730 : INFO : PROGRESS: at sentence #230000, processed 5184078 words, keeping 69958 word types\n",
      "2019-01-10 05:40:32,805 : INFO : PROGRESS: at sentence #240000, processed 5414566 words, keeping 71167 word types\n",
      "2019-01-10 05:40:32,876 : INFO : PROGRESS: at sentence #250000, processed 5631424 words, keeping 72351 word types\n",
      "2019-01-10 05:40:32,951 : INFO : PROGRESS: at sentence #260000, processed 5854257 words, keeping 73478 word types\n",
      "2019-01-10 05:40:33,023 : INFO : PROGRESS: at sentence #270000, processed 6078626 words, keeping 74767 word types\n",
      "2019-01-10 05:40:33,098 : INFO : PROGRESS: at sentence #280000, processed 6307307 words, keeping 76369 word types\n",
      "2019-01-10 05:40:33,171 : INFO : PROGRESS: at sentence #290000, processed 6533230 words, keeping 77839 word types\n",
      "2019-01-10 05:40:33,244 : INFO : PROGRESS: at sentence #300000, processed 6760761 words, keeping 79171 word types\n",
      "2019-01-10 05:40:33,318 : INFO : PROGRESS: at sentence #310000, processed 6988969 words, keeping 80480 word types\n",
      "2019-01-10 05:40:33,394 : INFO : PROGRESS: at sentence #320000, processed 7216728 words, keeping 81808 word types\n",
      "2019-01-10 05:40:33,464 : INFO : PROGRESS: at sentence #330000, processed 7441444 words, keeping 83030 word types\n",
      "2019-01-10 05:40:33,534 : INFO : PROGRESS: at sentence #340000, processed 7673974 words, keeping 84280 word types\n",
      "2019-01-10 05:40:33,601 : INFO : PROGRESS: at sentence #350000, processed 7900006 words, keeping 85425 word types\n",
      "2019-01-10 05:40:33,670 : INFO : PROGRESS: at sentence #360000, processed 8123236 words, keeping 86596 word types\n",
      "2019-01-10 05:40:33,755 : INFO : PROGRESS: at sentence #370000, processed 8353154 words, keeping 87708 word types\n",
      "2019-01-10 05:40:33,829 : INFO : PROGRESS: at sentence #380000, processed 8581103 words, keeping 88878 word types\n",
      "2019-01-10 05:40:33,908 : INFO : PROGRESS: at sentence #390000, processed 8813816 words, keeping 89907 word types\n",
      "2019-01-10 05:40:33,987 : INFO : PROGRESS: at sentence #400000, processed 9039547 words, keeping 90916 word types\n",
      "2019-01-10 05:40:34,061 : INFO : PROGRESS: at sentence #410000, processed 9263665 words, keeping 91880 word types\n",
      "2019-01-10 05:40:34,133 : INFO : PROGRESS: at sentence #420000, processed 9487604 words, keeping 92912 word types\n",
      "2019-01-10 05:40:34,208 : INFO : PROGRESS: at sentence #430000, processed 9718299 words, keeping 93932 word types\n",
      "2019-01-10 05:40:34,285 : INFO : PROGRESS: at sentence #440000, processed 9948146 words, keeping 94906 word types\n",
      "2019-01-10 05:40:34,361 : INFO : PROGRESS: at sentence #450000, processed 10174664 words, keeping 96036 word types\n",
      "2019-01-10 05:40:34,441 : INFO : PROGRESS: at sentence #460000, processed 10410449 words, keeping 97088 word types\n",
      "2019-01-10 05:40:34,518 : INFO : PROGRESS: at sentence #470000, processed 10641191 words, keeping 97933 word types\n",
      "2019-01-10 05:40:34,593 : INFO : PROGRESS: at sentence #480000, processed 10864381 words, keeping 98862 word types\n",
      "2019-01-10 05:40:34,669 : INFO : PROGRESS: at sentence #490000, processed 11094355 words, keeping 99871 word types\n",
      "2019-01-10 05:40:34,744 : INFO : PROGRESS: at sentence #500000, processed 11318945 words, keeping 100765 word types\n",
      "2019-01-10 05:40:34,819 : INFO : PROGRESS: at sentence #510000, processed 11547157 words, keeping 101699 word types\n",
      "2019-01-10 05:40:34,897 : INFO : PROGRESS: at sentence #520000, processed 11773556 words, keeping 102598 word types\n",
      "2019-01-10 05:40:34,974 : INFO : PROGRESS: at sentence #530000, processed 12000895 words, keeping 103400 word types\n",
      "2019-01-10 05:40:35,050 : INFO : PROGRESS: at sentence #540000, processed 12228506 words, keeping 104265 word types\n",
      "2019-01-10 05:40:35,127 : INFO : PROGRESS: at sentence #550000, processed 12456994 words, keeping 105133 word types\n",
      "2019-01-10 05:40:35,202 : INFO : PROGRESS: at sentence #560000, processed 12680909 words, keeping 105997 word types\n",
      "2019-01-10 05:40:35,277 : INFO : PROGRESS: at sentence #570000, processed 12912794 words, keeping 106787 word types\n",
      "2019-01-10 05:40:35,352 : INFO : PROGRESS: at sentence #580000, processed 13136994 words, keeping 107665 word types\n",
      "2019-01-10 05:40:35,428 : INFO : PROGRESS: at sentence #590000, processed 13365352 words, keeping 108501 word types\n",
      "2019-01-10 05:40:35,503 : INFO : PROGRESS: at sentence #600000, processed 13590494 words, keeping 109218 word types\n",
      "2019-01-10 05:40:35,580 : INFO : PROGRESS: at sentence #610000, processed 13814333 words, keeping 110092 word types\n",
      "2019-01-10 05:40:35,658 : INFO : PROGRESS: at sentence #620000, processed 14043771 words, keeping 110837 word types\n",
      "2019-01-10 05:40:35,738 : INFO : PROGRESS: at sentence #630000, processed 14271006 words, keeping 111610 word types\n",
      "2019-01-10 05:40:35,811 : INFO : PROGRESS: at sentence #640000, processed 14494594 words, keeping 112416 word types\n",
      "2019-01-10 05:40:35,885 : INFO : PROGRESS: at sentence #650000, processed 14723447 words, keeping 113196 word types\n",
      "2019-01-10 05:40:35,958 : INFO : PROGRESS: at sentence #660000, processed 14948965 words, keeping 113945 word types\n",
      "2019-01-10 05:40:36,032 : INFO : PROGRESS: at sentence #670000, processed 15175145 words, keeping 114643 word types\n",
      "2019-01-10 05:40:36,108 : INFO : PROGRESS: at sentence #680000, processed 15402930 words, keeping 115354 word types\n",
      "2019-01-10 05:40:36,180 : INFO : PROGRESS: at sentence #690000, processed 15627887 words, keeping 116131 word types\n",
      "2019-01-10 05:40:36,253 : INFO : PROGRESS: at sentence #700000, processed 15859212 words, keeping 116943 word types\n",
      "2019-01-10 05:40:36,325 : INFO : PROGRESS: at sentence #710000, processed 16085072 words, keeping 117596 word types\n",
      "2019-01-10 05:40:36,398 : INFO : PROGRESS: at sentence #720000, processed 16313209 words, keeping 118221 word types\n",
      "2019-01-10 05:40:36,470 : INFO : PROGRESS: at sentence #730000, processed 16542280 words, keeping 118954 word types\n",
      "2019-01-10 05:40:36,541 : INFO : PROGRESS: at sentence #740000, processed 16766267 words, keeping 119668 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-10 05:40:36,610 : INFO : PROGRESS: at sentence #750000, processed 16987629 words, keeping 120295 word types\n",
      "2019-01-10 05:40:36,678 : INFO : PROGRESS: at sentence #760000, processed 17209786 words, keeping 120930 word types\n",
      "2019-01-10 05:40:36,754 : INFO : PROGRESS: at sentence #770000, processed 17439959 words, keeping 121703 word types\n",
      "2019-01-10 05:40:36,833 : INFO : PROGRESS: at sentence #780000, processed 17673154 words, keeping 122402 word types\n",
      "2019-01-10 05:40:36,905 : INFO : PROGRESS: at sentence #790000, processed 17903065 words, keeping 123066 word types\n",
      "2019-01-10 05:40:36,952 : INFO : collected 123504 word types from a corpus of 18027659 raw words and 795538 sentences\n",
      "2019-01-10 05:40:36,954 : INFO : Loading a fresh vocabulary\n",
      "2019-01-10 05:40:37,067 : INFO : effective_min_count=40 retains 16490 unique words (13% of original 123504, drops 107014)\n",
      "2019-01-10 05:40:37,068 : INFO : effective_min_count=40 leaves 17468517 word corpus (96% of original 18027659, drops 559142)\n",
      "2019-01-10 05:40:37,124 : INFO : deleting the raw counts dictionary of 123504 items\n",
      "2019-01-10 05:40:37,134 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2019-01-10 05:40:37,135 : INFO : downsampling leaves estimated 12974575 word corpus (74.3% of prior 17468517)\n",
      "2019-01-10 05:40:37,184 : INFO : estimated required memory for 16490 words and 300 dimensions: 47821000 bytes\n",
      "2019-01-10 05:40:37,185 : INFO : resetting layer weights\n",
      "2019-01-10 05:40:37,489 : INFO : training model with 4 workers on 16490 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-01-10 05:40:38,496 : INFO : EPOCH 1 - PROGRESS: at 4.27% examples, 551776 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:39,503 : INFO : EPOCH 1 - PROGRESS: at 9.67% examples, 621881 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:40,509 : INFO : EPOCH 1 - PROGRESS: at 14.37% examples, 614585 words/s, in_qsize 7, out_qsize 0\n",
      "2019-01-10 05:40:41,515 : INFO : EPOCH 1 - PROGRESS: at 19.01% examples, 609015 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:42,525 : INFO : EPOCH 1 - PROGRESS: at 23.63% examples, 605371 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:43,535 : INFO : EPOCH 1 - PROGRESS: at 28.22% examples, 602746 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:44,546 : INFO : EPOCH 1 - PROGRESS: at 32.89% examples, 600758 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:45,556 : INFO : EPOCH 1 - PROGRESS: at 37.53% examples, 600314 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:46,559 : INFO : EPOCH 1 - PROGRESS: at 42.15% examples, 600487 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:47,563 : INFO : EPOCH 1 - PROGRESS: at 46.68% examples, 599092 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:48,576 : INFO : EPOCH 1 - PROGRESS: at 51.32% examples, 598767 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:49,583 : INFO : EPOCH 1 - PROGRESS: at 56.00% examples, 599401 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:50,591 : INFO : EPOCH 1 - PROGRESS: at 60.58% examples, 599331 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:51,600 : INFO : EPOCH 1 - PROGRESS: at 65.22% examples, 599273 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:52,601 : INFO : EPOCH 1 - PROGRESS: at 69.92% examples, 599975 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:53,603 : INFO : EPOCH 1 - PROGRESS: at 74.49% examples, 599666 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:54,628 : INFO : EPOCH 1 - PROGRESS: at 79.20% examples, 599490 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:55,631 : INFO : EPOCH 1 - PROGRESS: at 84.03% examples, 600799 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:56,640 : INFO : EPOCH 1 - PROGRESS: at 88.77% examples, 601400 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:57,653 : INFO : EPOCH 1 - PROGRESS: at 93.53% examples, 601797 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:58,661 : INFO : EPOCH 1 - PROGRESS: at 98.24% examples, 601993 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:40:59,012 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-10 05:40:59,021 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-10 05:40:59,031 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-10 05:40:59,037 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-10 05:40:59,039 : INFO : EPOCH - 1 : training on 18027659 raw words (12973316 effective words) took 21.5s, 602130 effective words/s\n",
      "2019-01-10 05:41:00,050 : INFO : EPOCH 2 - PROGRESS: at 4.53% examples, 584052 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:01,051 : INFO : EPOCH 2 - PROGRESS: at 9.28% examples, 596567 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:02,055 : INFO : EPOCH 2 - PROGRESS: at 14.09% examples, 603238 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:03,068 : INFO : EPOCH 2 - PROGRESS: at 18.90% examples, 604685 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:04,079 : INFO : EPOCH 2 - PROGRESS: at 23.57% examples, 603409 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:05,090 : INFO : EPOCH 2 - PROGRESS: at 28.22% examples, 602168 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:06,102 : INFO : EPOCH 2 - PROGRESS: at 32.94% examples, 601268 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:07,117 : INFO : EPOCH 2 - PROGRESS: at 37.64% examples, 601211 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:08,122 : INFO : EPOCH 2 - PROGRESS: at 42.25% examples, 601181 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:09,122 : INFO : EPOCH 2 - PROGRESS: at 46.89% examples, 601311 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:10,124 : INFO : EPOCH 2 - PROGRESS: at 51.37% examples, 599486 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:11,126 : INFO : EPOCH 2 - PROGRESS: at 56.00% examples, 599713 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:12,135 : INFO : EPOCH 2 - PROGRESS: at 60.64% examples, 600071 words/s, in_qsize 7, out_qsize 0\n",
      "2019-01-10 05:41:13,142 : INFO : EPOCH 2 - PROGRESS: at 65.17% examples, 599053 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:14,143 : INFO : EPOCH 2 - PROGRESS: at 69.69% examples, 598334 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:15,147 : INFO : EPOCH 2 - PROGRESS: at 74.22% examples, 597580 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:16,155 : INFO : EPOCH 2 - PROGRESS: at 78.83% examples, 597265 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:17,158 : INFO : EPOCH 2 - PROGRESS: at 83.38% examples, 596708 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:18,162 : INFO : EPOCH 2 - PROGRESS: at 88.00% examples, 596931 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:19,173 : INFO : EPOCH 2 - PROGRESS: at 92.71% examples, 597287 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:20,176 : INFO : EPOCH 2 - PROGRESS: at 97.43% examples, 597834 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:20,705 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-10 05:41:20,711 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-10 05:41:20,721 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-10 05:41:20,727 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-10 05:41:20,729 : INFO : EPOCH - 2 : training on 18027659 raw words (12973228 effective words) took 21.7s, 598200 effective words/s\n",
      "2019-01-10 05:41:21,734 : INFO : EPOCH 3 - PROGRESS: at 4.53% examples, 588038 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:22,736 : INFO : EPOCH 3 - PROGRESS: at 9.17% examples, 591546 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:23,736 : INFO : EPOCH 3 - PROGRESS: at 13.75% examples, 590949 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:24,751 : INFO : EPOCH 3 - PROGRESS: at 18.46% examples, 591773 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:25,763 : INFO : EPOCH 3 - PROGRESS: at 23.08% examples, 591358 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:26,775 : INFO : EPOCH 3 - PROGRESS: at 27.77% examples, 593183 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:27,782 : INFO : EPOCH 3 - PROGRESS: at 32.48% examples, 593966 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:28,784 : INFO : EPOCH 3 - PROGRESS: at 37.13% examples, 595017 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-10 05:41:29,793 : INFO : EPOCH 3 - PROGRESS: at 41.77% examples, 595344 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:30,796 : INFO : EPOCH 3 - PROGRESS: at 46.41% examples, 595960 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:31,805 : INFO : EPOCH 3 - PROGRESS: at 51.02% examples, 596198 words/s, in_qsize 7, out_qsize 0\n",
      "2019-01-10 05:41:32,805 : INFO : EPOCH 3 - PROGRESS: at 55.61% examples, 596161 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:33,813 : INFO : EPOCH 3 - PROGRESS: at 60.07% examples, 595176 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:34,822 : INFO : EPOCH 3 - PROGRESS: at 64.68% examples, 594919 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:35,822 : INFO : EPOCH 3 - PROGRESS: at 69.25% examples, 594996 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:36,823 : INFO : EPOCH 3 - PROGRESS: at 73.84% examples, 595063 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:37,828 : INFO : EPOCH 3 - PROGRESS: at 78.60% examples, 596199 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:38,831 : INFO : EPOCH 3 - PROGRESS: at 83.27% examples, 596499 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:39,842 : INFO : EPOCH 3 - PROGRESS: at 87.94% examples, 596912 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:40,846 : INFO : EPOCH 3 - PROGRESS: at 92.66% examples, 597520 words/s, in_qsize 7, out_qsize 0\n",
      "2019-01-10 05:41:41,858 : INFO : EPOCH 3 - PROGRESS: at 97.38% examples, 597793 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:42,402 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-10 05:41:42,408 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-10 05:41:42,415 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-10 05:41:42,421 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-10 05:41:42,423 : INFO : EPOCH - 3 : training on 18027659 raw words (12974583 effective words) took 21.7s, 598167 effective words/s\n",
      "2019-01-10 05:41:43,436 : INFO : EPOCH 4 - PROGRESS: at 4.53% examples, 583630 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:44,442 : INFO : EPOCH 4 - PROGRESS: at 9.28% examples, 594539 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:45,453 : INFO : EPOCH 4 - PROGRESS: at 13.98% examples, 595704 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:46,458 : INFO : EPOCH 4 - PROGRESS: at 18.62% examples, 594942 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:47,462 : INFO : EPOCH 4 - PROGRESS: at 23.25% examples, 594780 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:48,474 : INFO : EPOCH 4 - PROGRESS: at 27.83% examples, 593736 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:49,475 : INFO : EPOCH 4 - PROGRESS: at 32.60% examples, 595902 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:50,477 : INFO : EPOCH 4 - PROGRESS: at 37.31% examples, 597592 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:51,483 : INFO : EPOCH 4 - PROGRESS: at 41.94% examples, 597875 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:52,492 : INFO : EPOCH 4 - PROGRESS: at 46.62% examples, 598615 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:53,497 : INFO : EPOCH 4 - PROGRESS: at 51.32% examples, 599435 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:54,505 : INFO : EPOCH 4 - PROGRESS: at 56.00% examples, 599953 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:55,512 : INFO : EPOCH 4 - PROGRESS: at 60.58% examples, 599852 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:56,520 : INFO : EPOCH 4 - PROGRESS: at 65.17% examples, 599244 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:57,523 : INFO : EPOCH 4 - PROGRESS: at 69.69% examples, 598484 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:58,528 : INFO : EPOCH 4 - PROGRESS: at 74.33% examples, 598610 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:41:59,531 : INFO : EPOCH 4 - PROGRESS: at 78.93% examples, 598400 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:00,538 : INFO : EPOCH 4 - PROGRESS: at 83.66% examples, 598828 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:01,539 : INFO : EPOCH 4 - PROGRESS: at 88.26% examples, 599008 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:02,542 : INFO : EPOCH 4 - PROGRESS: at 92.93% examples, 599133 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:03,553 : INFO : EPOCH 4 - PROGRESS: at 97.64% examples, 599352 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:04,034 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-10 05:42:04,049 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-10 05:42:04,058 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-10 05:42:04,062 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-10 05:42:04,063 : INFO : EPOCH - 4 : training on 18027659 raw words (12972260 effective words) took 21.6s, 599541 effective words/s\n",
      "2019-01-10 05:42:05,069 : INFO : EPOCH 5 - PROGRESS: at 4.53% examples, 587935 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:06,080 : INFO : EPOCH 5 - PROGRESS: at 9.17% examples, 588491 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:07,087 : INFO : EPOCH 5 - PROGRESS: at 13.81% examples, 590096 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:08,094 : INFO : EPOCH 5 - PROGRESS: at 18.40% examples, 588704 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:09,098 : INFO : EPOCH 5 - PROGRESS: at 23.02% examples, 589865 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:10,098 : INFO : EPOCH 5 - PROGRESS: at 27.67% examples, 591948 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:11,100 : INFO : EPOCH 5 - PROGRESS: at 32.37% examples, 593336 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:12,107 : INFO : EPOCH 5 - PROGRESS: at 37.03% examples, 594098 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:13,113 : INFO : EPOCH 5 - PROGRESS: at 41.67% examples, 594799 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:14,122 : INFO : EPOCH 5 - PROGRESS: at 46.29% examples, 595104 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:15,124 : INFO : EPOCH 5 - PROGRESS: at 50.86% examples, 595094 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:16,126 : INFO : EPOCH 5 - PROGRESS: at 55.39% examples, 594483 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:17,126 : INFO : EPOCH 5 - PROGRESS: at 59.84% examples, 594011 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:18,145 : INFO : EPOCH 5 - PROGRESS: at 64.45% examples, 593406 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:19,151 : INFO : EPOCH 5 - PROGRESS: at 69.08% examples, 593869 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:20,152 : INFO : EPOCH 5 - PROGRESS: at 73.73% examples, 594437 words/s, in_qsize 7, out_qsize 0\n",
      "2019-01-10 05:42:21,154 : INFO : EPOCH 5 - PROGRESS: at 78.36% examples, 594866 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:22,161 : INFO : EPOCH 5 - PROGRESS: at 83.15% examples, 595926 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:23,164 : INFO : EPOCH 5 - PROGRESS: at 87.89% examples, 597006 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:24,183 : INFO : EPOCH 5 - PROGRESS: at 92.60% examples, 597123 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:25,190 : INFO : EPOCH 5 - PROGRESS: at 97.32% examples, 597556 words/s, in_qsize 8, out_qsize 0\n",
      "2019-01-10 05:42:25,745 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-10 05:42:25,756 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-10 05:42:25,766 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-10 05:42:25,772 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-10 05:42:25,773 : INFO : EPOCH - 5 : training on 18027659 raw words (12975461 effective words) took 21.7s, 597745 effective words/s\n",
      "2019-01-10 05:42:25,775 : INFO : training on a 90138295 raw words (64868848 effective words) took 108.3s, 599061 effective words/s\n",
      "2019-01-10 05:42:25,776 : INFO : saving Word2Vec object under ../input/word2vec_model_300dim_40minwords_10context_convert_10, separately None\n",
      "2019-01-10 05:42:25,778 : INFO : not storing attribute vectors_norm\n",
      "2019-01-10 05:42:25,781 : INFO : not storing attribute cum_table\n",
      "2019-01-10 05:42:25,973 : INFO : saved ../input/word2vec_model_300dim_40minwords_10context_convert_10\n"
     ]
    }
   ],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec\n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', \\\n",
    "                    level=logging.INFO)\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "EMBEDDING_DIM = 300  # Word vector dimensionality\n",
    "MIN_WORD_COUNT = 40  # Minimum word count. Kaggle set to 40, to avoid attaching too much importance to individual movie titles.\n",
    "NUM_THREADS = 4  # Number of threads to run in parallel\n",
    "CONTEXT = 10  # Context window size\n",
    "DOWNSAMPLING = 1e-3  # Downsample setting for frequent words\n",
    "WORD2VEC_MODEL_FILE = BASE_DIR + \\\n",
    "    \"word2vec_model_\" + \\\n",
    "    str(EMBEDDING_DIM) + \"dim_\" + \\\n",
    "    str(MIN_WORD_COUNT) + \"minwords_\" + \\\n",
    "    str(CONTEXT) + \"context_\" +\\\n",
    "    \"convert_10\"\n",
    "\n",
    "print \"Training the Word2Vec model...\"\n",
    "model = Word2Vec(sentences, workers=NUM_THREADS, \\\n",
    "                 size=EMBEDDING_DIM, min_count=MIN_WORD_COUNT, \\\n",
    "                 window=CONTEXT, sample=DOWNSAMPLING, seed=1)\n",
    "model.save(WORD2VEC_MODEL_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the txt file for FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['that s supposed to be entertainment'\n",
      " 'from the start the best actors are alec newman and joe absolom this is what british films are about good actors low money made into something decent'\n",
      " 'of course he redeems himself but only in the final episode and for no apparent reason'\n",
      " 'there is one or two decent performances including the guys who played jacob and fenner but it s like the director had no clue on how to work or use his thespians'\n",
      " 'dustin hoffman s performance as comic lenny bruce is brilliant and i agree with those who say he is one of the greatest actors in cinema history'\n",
      " 'i found it it sweet funny and adorable'\n",
      " 'the men can slaver over lollo if they like or her lollos she gave her name to a slang terms for breasts in french but the ladies have an even tastier morsel in the divine gerard philipe who is not only beautiful but can act'\n",
      " 'francesca annis is one of the most striking five zero ish women imaginable her acting rivals her beauty'\n",
      " 'i had enjoyed all three films and looking at the prolific veteran director s filmography i think it ll take me a very long while to watch all his films especially the tora san series'\n",
      " 'lead singer of the cruisers has disappeared he died in a car accident but his body was never recovered a reporter decides to write a story about the band']\n"
     ]
    }
   ],
   "source": [
    "sentences = pd.read_csv(\"../input/sentences_for_word2vec_convert_10.csv\", header = 0)\n",
    "sentences[\"sentences\"] = sentences[\"sentences\"].astype(str)\n",
    "sentences = sentences[\"sentences\"].tolist()\n",
    "print(np.random.choice(sentences, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sentences = open('../input/sentences_for_fasttext_convert_10.txt', 'w')\n",
    "for sentence in sentences:\n",
    "    output_sentences.write(sentence + '\\n')\n",
    "output_sentences.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
