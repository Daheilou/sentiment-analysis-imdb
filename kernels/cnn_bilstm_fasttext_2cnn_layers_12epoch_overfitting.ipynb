{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import os, re\n",
    "import nltk\n",
    "BASE_DIR = '../input/'\n",
    "LABELED_TRAIN_DF = BASE_DIR + 'labeled_train_clean_reviews.csv'\n",
    "TEST_DF = BASE_DIR + 'test_clean_reviews.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 25000 labeled train reviewsand 25000 test reviews\n"
     ]
    }
   ],
   "source": [
    "labeled_train = pd.read_csv(LABELED_TRAIN_DF, header = 0)\n",
    "test = pd.read_csv(TEST_DF, header = 0)\n",
    "labeled_train[\"review\"] = labeled_train[\"review\"].astype(str)\n",
    "test[\"review\"] = test[\"review\"].astype(str)\n",
    "print \"Read %d labeled train reviews\" \\\n",
    "          \"and %d test reviews\" % (labeled_train[\"review\"].size, test[\"review\"].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data leakage\n",
    "\n",
    "Check if test[\"sentiment\"] is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"sentiment\"] = test[\"id\"].map(lambda x: 1 if int(x.strip('\"').split(\"_\")[1]) >= 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import fastText\n",
    "EMBEDDING_DIM = 300  # Word vector dimensionality\n",
    "fasttext_model = fastText.load_model(\"../input/fasttext_300features_40minwords_10context.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean_reviews = labeled_train[\"review\"].tolist()\n",
    "test_clean_reviews = test[\"review\"].tolist()\n",
    "\n",
    "all_clean_reviews = train_clean_reviews + test_clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the mayor of hell   has the feel of an early dead end kids film  but with a much harder edge and very few light spots  preceding the first appearance of the dead enders by four years  james cagney has a full screen opening credit  even though technically  the  mayor  of the movie s title is actually portrayed by frankie darro  one of several boys sent to reform school during the opening scenes  darro s character is jimmy smith  a young tough who s befriended by  patsy  gargan  cagney   and is elected to the position when gargan takes a chance at humanizing conditions at a state reformatory warner brothers made a lot of these types of films  attempting to provide a conscience of sorts in an era that only too well knew about the effects of crime and poverty  this movie is quite gritty  with no apologies for ethnic stereotyping  as in the submissive posture of a black father in court or the way a jewish kid gets to run a candy shop in the reform school  the rules at the reformatory are simple enough   work hard and keep your mouth shut  step out of line and you answer personally to warden thompson  dudley digges  cagney s role in the story seems somewhat ambiguous  since even though he makes a serious effort to improve conditions inside the reformatory  on the outside he s still nominally in control of a criminal racket  the film s attempt to juggle this dichotomy falls short in my estimation  the finale attempts to wrap things up in a neat package as gargan awaits the outcome of a near fatal shooting of one of his henchmen  not exactly the kind of role modeling one would look for in a film like this warner brothers would sanitize some of the elements of this story in a  one  nine  three  eight  remake titled   crime school    featuring humphrey bogart in the cagney role  and billy halop in the frankie darro part  if you re partial to the dead end kids you ll probably like the latter film better  since it also offers familiar faces like leo gorcey  huntz hall  bobby jordan and gabriel dell  however the ending is somewhat muddied in that one too  with bogart s warden character involved in a cover up of a prison breakout  both films offer a romantic interest for the lead characters  in  mayor   madge evans is a reform minded nurse that falls for cagney s character curiously  a lot of james cagney s early films aren t commercially available  so you ll have to keep your eyes peeled for a screening on turner classics  or source the film from a private collector  personally  i can t get enough of this kind of stuff  and find intriguing points of interest in the films of all genres from the thirties and forties']\n"
     ]
    }
   ],
   "source": [
    "print(np.random.choice(all_clean_reviews, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Tokenizer found 101376 unique tokens\n"
     ]
    }
   ],
   "source": [
    "# We vectorize the text corpus by turning each text into a sequence of integers\n",
    "# Each integer is the index of a token in the dictionary\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "MAX_NUM_WORDS_FOR_KERAS_TOKENIZER = 200000\n",
    "#\n",
    "# num_words: the maximum number of words to keep, based on frequency.\n",
    "keras_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS_FOR_KERAS_TOKENIZER)\n",
    "#\n",
    "# fit_on_texts accepts a list of strings, a generator of strings or \n",
    "# a list of list of strings. In the last case, it assumes each entry of the lists to be a token.\n",
    "# Here we provide a list of strings.\n",
    "keras_tokenizer.fit_on_texts(all_clean_reviews)\n",
    "word_index = keras_tokenizer.word_index\n",
    "print('Keras Tokenizer found %s unique tokens' % len(word_index))\n",
    "#\n",
    "# texts_to_sequences transforms each text in texts to a sequence of integers.\n",
    "train_sequences = keras_tokenizer.texts_to_sequences(train_clean_reviews)\n",
    "test_sequences = keras_tokenizer.texts_to_sequences(test_clean_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pad all text sequences to the same length.\n",
    "# By default zeros are padded at the front.\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Set max length for each review sequence.\n",
    "MAX_SEQUENCE_LENGTH_FOR_KERAS_RNN = 500\n",
    "\n",
    "train_pad_sequences = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH_FOR_KERAS_RNN)\n",
    "test_pad_sequences = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH_FOR_KERAS_RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fawn', 29637)\n"
     ]
    }
   ],
   "source": [
    "print(word_index.items()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 1\n"
     ]
    }
   ],
   "source": [
    "# Prepare word embedding matrix\n",
    "\n",
    "# Choose the smaller number of the two as column length of the matrix\n",
    "num_words = min(MAX_NUM_WORDS_FOR_KERAS_TOKENIZER, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_matrix[i] = fasttext_model.get_word_vector(word)\n",
    "# Null word embeddings are words that don't exist in the embedding matrix\n",
    "# and are therefore represented as zero vectors.\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
    "# Null word embeddings is one because index 0 does not match any tokens. keras tokenizer uses 1-based index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly split 20000 pad sequences for training, 5000 for validation\n"
     ]
    }
   ],
   "source": [
    "# Split train_sequences into train and validation. Ratio: 80/20\n",
    "VALIDATION_SPLIT = 0.2\n",
    "np.random.seed(1234)\n",
    "\n",
    "# \n",
    "perm = np.random.permutation(len(train_sequences))\n",
    "index_train = perm[:int(len(train_sequences)*(1-VALIDATION_SPLIT))]\n",
    "index_val = perm[int(len(train_sequences)*(1-VALIDATION_SPLIT)):]\n",
    "\n",
    "x_train = train_pad_sequences[index_train]\n",
    "x_val = train_pad_sequences[index_val]\n",
    "y_train = labeled_train[\"sentiment\"][index_train].tolist()\n",
    "y_val = labeled_train[\"sentiment\"][index_val].tolist()\n",
    "\n",
    "print('Randomly split %d pad sequences for training, %d for validation' % (len(x_train) ,len(x_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_pad_sequences\n",
    "y_test = test[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Bidirectional, Conv1D, MaxPooling1D ,GlobalMaxPooling1D\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_rnn_model(dropout_cnn=0.5, dropout_rnn=0.2, num_filters=64, kernel_size=2):\n",
    "    model = Sequential()\n",
    "    \n",
    "    LSTM_UNITS = 32\n",
    "    LSTM_DROPOUT = 0.\n",
    "    LSTM_RECCURENT_DROPOUT = 0.\n",
    "\n",
    "    embedding_layer = Embedding(\n",
    "            num_words,\n",
    "            EMBEDDING_DIM,\n",
    "            weights=[embedding_matrix],\n",
    "            input_length=MAX_SEQUENCE_LENGTH_FOR_KERAS_RNN,\n",
    "            trainable=False)\n",
    "    output_layer = Dense(1, activation='sigmoid')\n",
    "    \n",
    "    model.add(embedding_layer)\n",
    "    model.add(Conv1D(filters=num_filters, kernel_size=kernel_size, padding='valid', activation='relu', strides=1))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(filters=num_filters, kernel_size=kernel_size, padding='valid', activation='relu', strides=1))\n",
    "    # Cannot use GlobalMaxPooling since you're feeding it into RNN\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_cnn))\n",
    "    model.add(Bidirectional(LSTM(LSTM_UNITS, \n",
    "                                 dropout=LSTM_DROPOUT, \n",
    "                                 recurrent_dropout=LSTM_RECCURENT_DROPOUT\n",
    "                                )))\n",
    "    model.add(Dropout(dropout_rnn))\n",
    "    model.add(output_layer)\n",
    "    \n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_rnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 300)          30413100  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 499, 64)           38464     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 249, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 248, 64)           8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 124, 64)           0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 124, 64)           4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 124, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 30,488,877\n",
      "Trainable params: 75,777\n",
      "Non-trainable params: 30,413,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/12\n",
      "20000/20000 [==============================] - 141s 7ms/step - loss: 0.2990 - acc: 0.8776 - val_loss: 0.2700 - val_acc: 0.8870\n",
      "Epoch 2/12\n",
      "20000/20000 [==============================] - 140s 7ms/step - loss: 0.2698 - acc: 0.8919 - val_loss: 0.3335 - val_acc: 0.8668\n",
      "Epoch 3/12\n",
      "20000/20000 [==============================] - 140s 7ms/step - loss: 0.2551 - acc: 0.8997 - val_loss: 0.2523 - val_acc: 0.9022\n",
      "Epoch 4/12\n",
      "20000/20000 [==============================] - 140s 7ms/step - loss: 0.2307 - acc: 0.9107 - val_loss: 0.2616 - val_acc: 0.9012\n",
      "Epoch 5/12\n",
      "20000/20000 [==============================] - 139s 7ms/step - loss: 0.2078 - acc: 0.9203 - val_loss: 0.2642 - val_acc: 0.8960\n",
      "Epoch 6/12\n",
      "20000/20000 [==============================] - 139s 7ms/step - loss: 0.1879 - acc: 0.9291 - val_loss: 0.2725 - val_acc: 0.8826\n",
      "Epoch 7/12\n",
      "20000/20000 [==============================] - 139s 7ms/step - loss: 0.1700 - acc: 0.9379 - val_loss: 0.2609 - val_acc: 0.8990\n",
      "Epoch 8/12\n",
      "20000/20000 [==============================] - 137s 7ms/step - loss: 0.1449 - acc: 0.9490 - val_loss: 0.2790 - val_acc: 0.8952\n",
      "Epoch 9/12\n",
      "20000/20000 [==============================] - 137s 7ms/step - loss: 0.1335 - acc: 0.9538 - val_loss: 0.2792 - val_acc: 0.9010\n",
      "Epoch 10/12\n",
      "20000/20000 [==============================] - 137s 7ms/step - loss: 0.1120 - acc: 0.9618 - val_loss: 0.2849 - val_acc: 0.8928\n",
      "Epoch 11/12\n",
      "20000/20000 [==============================] - 137s 7ms/step - loss: 0.1044 - acc: 0.9648 - val_loss: 0.3241 - val_acc: 0.8874\n",
      "Epoch 12/12\n",
      "20000/20000 [==============================] - 136s 7ms/step - loss: 0.0947 - acc: 0.9669 - val_loss: 0.4579 - val_acc: 0.8684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f38911f0510>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size: number of samples per gradient update\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=12, validation_data=[x_val, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_binary = map(lambda predict: 1 if predict > 0.5 else 0, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for CNN-BiLSTM model is : 0.86704.\n"
     ]
    }
   ],
   "source": [
    "print(\"The AUC score for CNN-BiLSTM model is : %.5f.\" %roc_auc_score(y_test, y_test_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the test results\n",
    "output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": y_test_pred_binary})\n",
    "output.to_csv(os.path.join('../', 'output', \"cnn_bilstm_fasttext_2cnn_layers_12epoch.csv\"), index=False, quoting=3)\n",
    "print \"Wrote to cnn_bilstm_fasttext_2cnn_layers_12epoch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
